{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d7c013-ec92-45ad-af9d-24b1e4423044",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /u/achaudhry3/.local/lib/python3.9/site-packages (4.1.1)\n",
      "Requirement already satisfied: transformers in /u/achaudhry3/.local/lib/python3.9/site-packages (4.56.2)\n",
      "Requirement already satisfied: torch in /u/achaudhry3/.local/lib/python3.9/site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: accelerate in /u/achaudhry3/.local/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: wandb in /u/achaudhry3/.local/lib/python3.9/site-packages (0.22.1)\n",
      "Requirement already satisfied: filelock in /sw/external/python/anaconda3/lib/python3.9/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /u/achaudhry3/.local/lib/python3.9/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /u/achaudhry3/.local/lib/python3.9/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /sw/external/python/anaconda3/lib/python3.9/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /u/achaudhry3/.local/lib/python3.9/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /u/achaudhry3/.local/lib/python3.9/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /sw/external/python/anaconda3/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /u/achaudhry3/.local/lib/python3.9/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /u/achaudhry3/.local/lib/python3.9/site-packages (from datasets) (0.35.1)\n",
      "Requirement already satisfied: packaging in /sw/external/python/anaconda3/lib/python3.9/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.8.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /u/achaudhry3/.local/lib/python3.9/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /u/achaudhry3/.local/lib/python3.9/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /u/achaudhry3/.local/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /u/achaudhry3/.local/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /sw/external/python/anaconda3/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from torch) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /u/achaudhry3/.local/lib/python3.9/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from triton==3.3.1->torch) (68.0.0)\n",
      "Requirement already satisfied: psutil in /sw/external/python/anaconda3/lib/python3.9/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: click>=8.0.1 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: eval-type-backport in /u/achaudhry3/.local/lib/python3.9/site-packages (from wandb) (0.2.2)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /u/achaudhry3/.local/lib/python3.9/site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /sw/external/python/anaconda3/lib/python3.9/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.15.0 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: pydantic<3 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from wandb) (1.10.12)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /u/achaudhry3/.local/lib/python3.9/site-packages (from wandb) (2.39.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /u/achaudhry3/.local/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /u/achaudhry3/.local/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /sw/external/python/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers torch accelerate wandb\n",
    "\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce17f628-ff25-4b8c-b3b4-147852007ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Training set size: 2646\n",
      "\n",
      "Available splits in train_ds: ['train']\n",
      "Available splits in test_ds: ['train']\n",
      "\n",
      "Using test split: 'train'\n",
      "Test set size: 50\n",
      "\n",
      "Sample training example:\n",
      "{'task_id': 667, 'code': '#lang racket\\n\\n;; Function to count vowels in a string based on a given set of vowels\\n(define (count-vowels input-string vowels-string)\\n  (define vowels (string->list vowels-string))\\n  (define (is-vowel? char)\\n    (member char vowels))\\n  \\n  (define (count-char char)\\n    (if (is-vowel? char) 1 0))\\n  \\n  (define (count-vowels-in-string str)\\n    (foldl (lambda (char count) (+ count (count-char char))) 0 (string->list str)))\\n  \\n  (count-vowels-in-string input-string))\\n\\n;; Read input from standard input\\n(define input-string (string-downcase (read-line)))\\n(define vowels-string (string-downcase (read-line)))\\n\\n;; Call the function and print the result\\n(display (count-vowels input-string vowels-string))\\n', 'test_cases': {'input': ['corner\\nAaEeIiOoUu', 'valid\\nAaEeIiOoUu', 'true\\nAaEeIiOoUu'], 'output': ['2', '2', '2']}, 'lang': 'racket', 'timeout_s': 30.0, 'result': 'success', 'stdout': None, 'stderr': '', 'exit_code': None, 'description': 'Write a function to count the number of vowels in a string, given a specific set of vowels. The function should return the count of characters in the input string that are present in the vowels string.', 'input_format': 'The input consists of two lines. The first line is the input string, the second line is the string containing the vowels to check.', 'output_format': 'The output is a single integer representing the count of vowels in the input string according to the given vowels.'}\n",
      "\n",
      "==================================================\n",
      "Sample test example:\n",
      "{'description': 'Given a list of lists, write a function to find the list with the maximum length using a lambda function. Return a tuple containing the length of the longest list and the list itself.', 'input_format': 'The first line contains an integer N, the number of lists. This is followed by N lines, each containing space-separated integers representing a list.', 'output_format': 'The output is the length of the longest list followed by the elements of the longest list, all separated by spaces.', 'tests': [{'input': '5\\n0\\n1 3\\n5 7\\n9 11\\n13 15 17', 'output': '3 13 15 17'}, {'input': '5\\n1 2 3 4 5\\n1 2 3 4\\n1 2 3\\n1 2\\n1', 'output': '5 1 2 3 4 5'}, {'input': '3\\n3 4 5\\n6 7 8 9\\n10 11 12', 'output': '4 6 7 8 9'}], 'task_id': 393}\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 (Fixed): Load Datasets and Inspect Structure\n",
    "import datasets\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_ds = datasets.load_dataset(\"nuprl/engineering-llm-systems\", \"mbpp-rkt-correct-executions\")\n",
    "test_ds = datasets.load_dataset(\"nuprl/engineering-llm-systems\", \"mbpp-rkt-test-problems\")\n",
    "\n",
    "print(f\"Training set size: {len(train_ds['train'])}\")\n",
    "\n",
    "# Check what splits are available in test_ds\n",
    "print(f\"\\nAvailable splits in train_ds: {list(train_ds.keys())}\")\n",
    "print(f\"Available splits in test_ds: {list(test_ds.keys())}\")\n",
    "\n",
    "# Get the correct split name for test dataset\n",
    "test_split_name = list(test_ds.keys())[0]\n",
    "print(f\"\\nUsing test split: '{test_split_name}'\")\n",
    "print(f\"Test set size: {len(test_ds[test_split_name])}\")\n",
    "\n",
    "# Inspect a sample\n",
    "print(\"\\nSample training example:\")\n",
    "print(train_ds['train'][0])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Sample test example:\")\n",
    "print(test_ds[test_split_name][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96028971-11db-48f9-b119-4240b3118bae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prompt generated:\n",
      "#lang racket\n",
      "\n",
      ";; Given a list of lists, write a function to find the list with the maximum length using a lambda function. Return a tuple containing the length of the longest list and the list itself.\n",
      ";; Input format: The first line contains an integer N, the number of lists. This is followed by N lines, each containing space-separated integers representing a list.\n",
      ";; Output format: The output is the length of the longest list followed by the elements of the longest list, all separated by spaces.\n",
      "\n",
      "\n",
      "Prompt length: 503\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 (Fixed): Racket Execution Helper Functions\n",
    "def execute_racket_code(code, test_input=None, timeout=5):\n",
    "    \"\"\"Execute Racket code and return success status.\"\"\"\n",
    "    temp_file = None\n",
    "    try:\n",
    "        # Create a temporary file for the Racket code\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.rkt', delete=False) as f:\n",
    "            f.write(code)\n",
    "            temp_file = f.name\n",
    "        \n",
    "        # Run the Racket code\n",
    "        result = subprocess.run(\n",
    "            ['racket', temp_file],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=timeout,\n",
    "            input=test_input if test_input else None,\n",
    "            check=False\n",
    "        )\n",
    "        \n",
    "        return result.returncode == 0, result.stdout.strip(), result.stderr\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"\", \"Timeout\"\n",
    "    except Exception as e:\n",
    "        return False, \"\", str(e)\n",
    "    finally:\n",
    "        if temp_file and os.path.exists(temp_file):\n",
    "            try:\n",
    "                os.unlink(temp_file)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def clip_racket_completion(text, prompt):\n",
    "    \"\"\"Clip generated Racket code at natural stopping points.\"\"\"\n",
    "    if text.startswith(prompt):\n",
    "        text = text[len(prompt):]\n",
    "    \n",
    "    # Racket-specific stopping points\n",
    "    stop_strings = [\"\\n\\n;; \", \"\\n#lang\"]\n",
    "    min_pos = len(text)\n",
    "    \n",
    "    for stop in stop_strings:\n",
    "        pos = text.find(stop)\n",
    "        if pos != -1 and pos < min_pos:\n",
    "            min_pos = pos\n",
    "    \n",
    "    return text[:min_pos]\n",
    "\n",
    "def construct_prompt_from_problem(problem):\n",
    "    \"\"\"Construct a Racket prompt from a test problem.\"\"\"\n",
    "    prompt = \"#lang racket\\n\\n\"\n",
    "    prompt += f\";; {problem['description']}\\n\"\n",
    "    prompt += f\";; Input format: {problem['input_format']}\\n\"\n",
    "    prompt += f\";; Output format: {problem['output_format']}\\n\\n\"\n",
    "    return prompt\n",
    "\n",
    "# Test the function with a sample\n",
    "sample_problem = test_ds['train'][0]\n",
    "test_prompt = construct_prompt_from_problem(sample_problem)\n",
    "print(\"Test prompt generated:\")\n",
    "print(test_prompt)\n",
    "print(f\"Prompt length: {len(test_prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd808b41-ce05-4594-a400-3877f2ce0314",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model...\n",
      "Using device: cuda\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load Base Model for Evaluation\n",
    "print(\"Loading base model...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-1.7B-Base\")\n",
    "if device != \"cpu\":\n",
    "    model = model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-1.7B-Base\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8777f-930a-46ce-b7cc-14dc74dc5df9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/50: Task 393\n",
      "  Prompt length: 503 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_393.json\n",
      "Processing 2/50: Task 71\n",
      "  Prompt length: 337 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_71.json\n",
      "Processing 3/50: Task 97\n",
      "  Prompt length: 585 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_97.json\n",
      "Processing 4/50: Task 353\n",
      "  Prompt length: 433 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_353.json\n",
      "Processing 5/50: Task 307\n",
      "  Prompt length: 571 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_307.json\n",
      "Processing 6/50: Task 64\n",
      "  Prompt length: 432 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_64.json\n",
      "Processing 7/50: Task 445\n",
      "  Prompt length: 554 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_445.json\n",
      "Processing 8/50: Task 205\n",
      "  Prompt length: 428 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_205.json\n",
      "Processing 9/50: Task 333\n",
      "  Prompt length: 393 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_333.json\n",
      "Processing 10/50: Task 498\n",
      "  Prompt length: 215 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_498.json\n",
      "Processing 11/50: Task 178\n",
      "  Prompt length: 386 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_178.json\n",
      "Processing 12/50: Task 342\n",
      "  Prompt length: 520 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_342.json\n",
      "Processing 13/50: Task 268\n",
      "  Prompt length: 184 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_268.json\n",
      "Processing 14/50: Task 51\n",
      "  Prompt length: 178 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_51.json\n",
      "Processing 15/50: Task 484\n",
      "  Prompt length: 537 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_484.json\n",
      "Processing 16/50: Task 322\n",
      "  Prompt length: 313 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n",
      "  Generating sample 4/5\n",
      "  Generating sample 5/5\n",
      "  Saved to completions_base_model/task_322.json\n",
      "Processing 17/50: Task 443\n",
      "  Prompt length: 269 characters\n",
      "  Generating sample 1/5\n",
      "  Generating sample 2/5\n",
      "  Generating sample 3/5\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 (Fixed with debugging): Generate Completions for Base Model\n",
    "def generate_completions_for_dataset(model, tokenizer, dataset, output_dir, \n",
    "                                     num_samples=5, temperature=0.2, top_p=0.95):\n",
    "    \"\"\"Generate completions for all problems in dataset.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for idx, problem in enumerate(dataset):\n",
    "        task_id = problem[\"task_id\"]\n",
    "        output_file = output_dir / f\"task_{task_id}.json\"\n",
    "        \n",
    "        if output_file.exists():\n",
    "            print(f\"Skipping task {task_id} (already exists)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing {idx+1}/{len(dataset)}: Task {task_id}\")\n",
    "        \n",
    "        # Construct prompt from problem description\n",
    "        prompt = construct_prompt_from_problem(problem)\n",
    "        \n",
    "        # Debug: Check if prompt is valid\n",
    "        if not prompt or len(prompt) == 0:\n",
    "            print(f\"  ERROR: Empty prompt for task {task_id}\")\n",
    "            print(f\"  Problem keys: {problem.keys()}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Prompt length: {len(prompt)} characters\")\n",
    "        \n",
    "        # Tokenize\n",
    "        try:\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            if device != \"cpu\":\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR during tokenization: {e}\")\n",
    "            print(f\"  Prompt: {prompt[:200]}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate multiple samples\n",
    "        completions = []\n",
    "        for sample_idx in range(num_samples):\n",
    "            print(f\"  Generating sample {sample_idx+1}/{num_samples}\")\n",
    "            \n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=400,\n",
    "                        temperature=temperature,\n",
    "                        top_p=top_p,\n",
    "                        do_sample=True,\n",
    "                        pad_token_id=tokenizer.pad_token_id,\n",
    "                        eos_token_id=tokenizer.eos_token_id\n",
    "                    )\n",
    "                \n",
    "                generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                completion = clip_racket_completion(generated_text, prompt)\n",
    "                completions.append(completion)\n",
    "            except Exception as e:\n",
    "                print(f\"  ERROR during generation: {e}\")\n",
    "                completions.append(\"\")  # Add empty completion on error\n",
    "        \n",
    "        # Save results\n",
    "        result = {\n",
    "            \"task_id\": task_id,\n",
    "            \"prompt\": prompt,\n",
    "            \"completions\": completions,\n",
    "            \"tests\": problem[\"tests\"]\n",
    "        }\n",
    "        \n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        print(f\"  Saved to {output_file}\")\n",
    "    \n",
    "    print(\"Completion generation done!\")\n",
    "\n",
    "# Generate completions for base model\n",
    "generate_completions_for_dataset(\n",
    "    model, tokenizer, test_ds['train'], \n",
    "    \"completions_base_model\",\n",
    "    num_samples=5,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b17112-8301-4f06-a7fa-5ab2c489be6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
